{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Is it easy or hard to break up a sentence into words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Intraterrestrials comprise a vast still-mysterious ecosystem in Earth’s crust containing as many (or more) living microbial cells than are on Earth’s surface. We know this from scientists such as myself going out on scientific drilling ships that sample deep marine sediments or drilling deep into continental crust, laboriously counting the number of cells we find there, and extrapolating out to the rest of the world. The deepest we’ve found intraterrestrials thus far is about 5 km down.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intraterrestrials',\n",
       " 'comprise',\n",
       " 'a',\n",
       " 'vast',\n",
       " 'still-mysterious',\n",
       " 'ecosystem',\n",
       " 'in',\n",
       " 'Earth’s',\n",
       " 'crust',\n",
       " 'containing',\n",
       " 'as',\n",
       " 'many',\n",
       " '(or',\n",
       " 'more)',\n",
       " 'living',\n",
       " 'microbial',\n",
       " 'cells',\n",
       " 'than',\n",
       " 'are',\n",
       " 'on',\n",
       " 'Earth’s',\n",
       " 'surface.',\n",
       " 'We',\n",
       " 'know',\n",
       " 'this',\n",
       " 'from',\n",
       " 'scientists',\n",
       " 'such',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'going',\n",
       " 'out',\n",
       " 'on',\n",
       " 'scientific',\n",
       " 'drilling',\n",
       " 'ships',\n",
       " 'that',\n",
       " 'sample',\n",
       " 'deep',\n",
       " 'marine',\n",
       " 'sediments',\n",
       " 'or',\n",
       " 'drilling',\n",
       " 'deep',\n",
       " 'into',\n",
       " 'continental',\n",
       " 'crust,',\n",
       " 'laboriously',\n",
       " 'counting',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'cells',\n",
       " 'we',\n",
       " 'find',\n",
       " 'there,',\n",
       " 'and',\n",
       " 'extrapolating',\n",
       " 'out',\n",
       " 'to',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world.',\n",
       " 'The',\n",
       " 'deepest',\n",
       " 'we’ve',\n",
       " 'found',\n",
       " 'intraterrestrials',\n",
       " 'thus',\n",
       " 'far',\n",
       " 'is',\n",
       " 'about',\n",
       " '5',\n",
       " 'km',\n",
       " 'down.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance this looks reasonable. However: \n",
    "\n",
    "* (or\n",
    "* surface.\n",
    "\n",
    "Also possibly problematic: \n",
    "* Earth's\n",
    "* we've\n",
    "\n",
    "Let's tackle the first problem first. \n",
    "\n",
    "We use regular expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intraterrestrials', 'comprise', 'a', 'vast', 'still-mysterious', 'ecosystem', 'in', 'Earth’s', 'crust', 'containing', 'as', 'many', 'or', 'more', 'living', 'microbial', 'cells', 'than', 'are', 'on', 'Earth’s', 'surface', 'We', 'know', 'this', 'from', 'scientists', 'such', 'as', 'myself', 'going', 'out', 'on', 'scientific', 'drilling', 'ships', 'that', 'sample', 'deep', 'marine', 'sediments', 'or', 'drilling', 'deep', 'into', 'continental', 'crust', 'laboriously', 'counting', 'the', 'number', 'of', 'cells', 'we', 'find', 'there', 'and', 'extrapolating', 'out', 'to', 'the', 'rest', 'of', 'the', 'world', 'The', 'deepest', 'we’ve', 'found', 'intraterrestrials', 'thus', 'far', 'is', 'about', '5', 'km', 'down', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(re.split(r'[ .!,:;()]+', text ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "What is better, what is still not great?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to splitting on punctuation, re also lets us match punctuation symbols and spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(17, 18), match=' '>,\n",
       " <re.Match object; span=(26, 27), match=' '>,\n",
       " <re.Match object; span=(28, 29), match=' '>,\n",
       " <re.Match object; span=(33, 34), match=' '>,\n",
       " <re.Match object; span=(50, 51), match=' '>,\n",
       " <re.Match object; span=(60, 61), match=' '>,\n",
       " <re.Match object; span=(63, 64), match=' '>,\n",
       " <re.Match object; span=(71, 72), match=' '>,\n",
       " <re.Match object; span=(77, 78), match=' '>,\n",
       " <re.Match object; span=(88, 89), match=' '>,\n",
       " <re.Match object; span=(91, 92), match=' '>,\n",
       " <re.Match object; span=(96, 98), match=' ('>,\n",
       " <re.Match object; span=(100, 101), match=' '>,\n",
       " <re.Match object; span=(105, 107), match=') '>,\n",
       " <re.Match object; span=(113, 114), match=' '>,\n",
       " <re.Match object; span=(123, 124), match=' '>,\n",
       " <re.Match object; span=(129, 130), match=' '>,\n",
       " <re.Match object; span=(134, 135), match=' '>,\n",
       " <re.Match object; span=(138, 139), match=' '>,\n",
       " <re.Match object; span=(141, 142), match=' '>,\n",
       " <re.Match object; span=(149, 150), match=' '>,\n",
       " <re.Match object; span=(157, 159), match='. '>,\n",
       " <re.Match object; span=(161, 162), match=' '>,\n",
       " <re.Match object; span=(166, 167), match=' '>,\n",
       " <re.Match object; span=(171, 172), match=' '>,\n",
       " <re.Match object; span=(176, 177), match=' '>,\n",
       " <re.Match object; span=(187, 188), match=' '>,\n",
       " <re.Match object; span=(192, 193), match=' '>,\n",
       " <re.Match object; span=(195, 196), match=' '>,\n",
       " <re.Match object; span=(202, 203), match=' '>,\n",
       " <re.Match object; span=(208, 209), match=' '>,\n",
       " <re.Match object; span=(212, 213), match=' '>,\n",
       " <re.Match object; span=(215, 216), match=' '>,\n",
       " <re.Match object; span=(226, 227), match=' '>,\n",
       " <re.Match object; span=(235, 236), match=' '>,\n",
       " <re.Match object; span=(241, 242), match=' '>,\n",
       " <re.Match object; span=(246, 247), match=' '>,\n",
       " <re.Match object; span=(253, 254), match=' '>,\n",
       " <re.Match object; span=(258, 259), match=' '>,\n",
       " <re.Match object; span=(265, 266), match=' '>,\n",
       " <re.Match object; span=(275, 276), match=' '>,\n",
       " <re.Match object; span=(278, 279), match=' '>,\n",
       " <re.Match object; span=(287, 288), match=' '>,\n",
       " <re.Match object; span=(292, 293), match=' '>,\n",
       " <re.Match object; span=(297, 298), match=' '>,\n",
       " <re.Match object; span=(309, 310), match=' '>,\n",
       " <re.Match object; span=(315, 317), match=', '>,\n",
       " <re.Match object; span=(328, 329), match=' '>,\n",
       " <re.Match object; span=(337, 338), match=' '>,\n",
       " <re.Match object; span=(341, 342), match=' '>,\n",
       " <re.Match object; span=(348, 349), match=' '>,\n",
       " <re.Match object; span=(351, 352), match=' '>,\n",
       " <re.Match object; span=(357, 358), match=' '>,\n",
       " <re.Match object; span=(360, 361), match=' '>,\n",
       " <re.Match object; span=(365, 366), match=' '>,\n",
       " <re.Match object; span=(371, 373), match=', '>,\n",
       " <re.Match object; span=(376, 377), match=' '>,\n",
       " <re.Match object; span=(390, 391), match=' '>,\n",
       " <re.Match object; span=(394, 395), match=' '>,\n",
       " <re.Match object; span=(397, 398), match=' '>,\n",
       " <re.Match object; span=(401, 402), match=' '>,\n",
       " <re.Match object; span=(406, 407), match=' '>,\n",
       " <re.Match object; span=(409, 410), match=' '>,\n",
       " <re.Match object; span=(413, 414), match=' '>,\n",
       " <re.Match object; span=(419, 421), match='. '>,\n",
       " <re.Match object; span=(424, 425), match=' '>,\n",
       " <re.Match object; span=(432, 433), match=' '>,\n",
       " <re.Match object; span=(438, 439), match=' '>,\n",
       " <re.Match object; span=(444, 445), match=' '>,\n",
       " <re.Match object; span=(462, 463), match=' '>,\n",
       " <re.Match object; span=(467, 468), match=' '>,\n",
       " <re.Match object; span=(471, 472), match=' '>,\n",
       " <re.Match object; span=(474, 475), match=' '>,\n",
       " <re.Match object; span=(480, 481), match=' '>,\n",
       " <re.Match object; span=(482, 483), match=' '>,\n",
       " <re.Match object; span=(485, 486), match=' '>,\n",
       " <re.Match object; span=(490, 491), match='.'>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(re.finditer(r'[ .!,:;()]+', text ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tools that, rather than swallowing punctuation, will split it off into separate \"words\". They also deal with things like \"we've\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install nltk\n",
    "import nltk\n",
    "nltk.download(\"punct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intraterrestrials',\n",
       " 'comprise',\n",
       " 'a',\n",
       " 'vast',\n",
       " 'still-mysterious',\n",
       " 'ecosystem',\n",
       " 'in',\n",
       " 'Earth',\n",
       " '’',\n",
       " 's',\n",
       " 'crust',\n",
       " 'containing',\n",
       " 'as',\n",
       " 'many',\n",
       " '(',\n",
       " 'or',\n",
       " 'more',\n",
       " ')',\n",
       " 'living',\n",
       " 'microbial',\n",
       " 'cells',\n",
       " 'than',\n",
       " 'are',\n",
       " 'on',\n",
       " 'Earth',\n",
       " '’',\n",
       " 's',\n",
       " 'surface',\n",
       " '.',\n",
       " 'We',\n",
       " 'know',\n",
       " 'this',\n",
       " 'from',\n",
       " 'scientists',\n",
       " 'such',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'going',\n",
       " 'out',\n",
       " 'on',\n",
       " 'scientific',\n",
       " 'drilling',\n",
       " 'ships',\n",
       " 'that',\n",
       " 'sample',\n",
       " 'deep',\n",
       " 'marine',\n",
       " 'sediments',\n",
       " 'or',\n",
       " 'drilling',\n",
       " 'deep',\n",
       " 'into',\n",
       " 'continental',\n",
       " 'crust',\n",
       " ',',\n",
       " 'laboriously',\n",
       " 'counting',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'cells',\n",
       " 'we',\n",
       " 'find',\n",
       " 'there',\n",
       " ',',\n",
       " 'and',\n",
       " 'extrapolating',\n",
       " 'out',\n",
       " 'to',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'The',\n",
       " 'deepest',\n",
       " 'we',\n",
       " '’',\n",
       " 've',\n",
       " 'found',\n",
       " 'intraterrestrials',\n",
       " 'thus',\n",
       " 'far',\n",
       " 'is',\n",
       " 'about',\n",
       " '5',\n",
       " 'km',\n",
       " 'down',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
