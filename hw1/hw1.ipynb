{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 1, Applications of Natural Language Processing, Spring 2026\n",
    "\n",
    "#### Due Tuesday February 24 on Gradescope. Please see detailed submission instructions below.  120 points total.\n",
    "\n",
    "##### How to do this problem set:\n",
    "\n",
    "- Use Python version 3.  We strongly suggest installing Python from the [Anaconda Individual Edition](https://docs.anaconda.com/anaconda/) software package.\n",
    "\n",
    "- If you are on Windows, you will need to install a package to use Unix commands. We suggest [Windows Subsystem for Linux](https://learn.microsoft.com/en-us/windows/wsl/install) or [Cygwin](https://www.cygwin.com).\n",
    "\n",
    "- Download [`large_movie_review_dataset.zip`](https://drive.google.com/file/d/1YfrrJkwZXk8qJiq7PDD_UqJ3qWowA2Pu/view?usp=drive_link). and also `lotr_script.txt` (in this zip file). We will use these two datasets in this homework. The first dataset may take a long time to unzip. \n",
    "\n",
    "- Most of these questions require writing Python code or Unix commands and computing results, while the remainder have textual answers. To complete this assignment, you will need to fill out the supporting files, `hw1.py` and `hw1.sh`.\n",
    "\n",
    "- For all of the textual answers, replace the placeholder text (\"Answer in one or two sentences here.\") with your answer.\n",
    "\n",
    "- This assignment is designed so that you can run all cells in a few minutes of computation time. If it is taking longer than that, you probably have a mistake in your code.\n",
    "\n",
    "##### How to submit this problem set:\n",
    "- Write all the answers in this ipython notebook. Once you are finished, (1) Generate a PDF via (File -> Download As -> PDF)  (2) Upload your pdf file to Gradescope.  (3) Compress `hw1.py`, `hw1.sh`, and `hw1.ipynb` into one zip file and upload to Gradescope.\n",
    "\n",
    "- **Important:** Check your PDF before you turn it in to gradescope to make sure it exported correctly. If ipython notebook gets confused about your syntax it will sometimes terminate the PDF creation routine early. You are responsible for checking for these errors. If your whole PDF does not print, try running on the commandline `jupyter nbconvert --to pdf hw1.ipynb` to identify and fix any syntax errors that might be causing problems.\n",
    "\n",
    "- **Important:** When creating your final version of the PDF to hand in, please do a fresh restart and execute every cell in order. Then you'll be sure it's actually right. One convenient way to do this is by clicking `Cell -> Run All` in the notebook menu.\n",
    "\n",
    "- If you are having trouble with PDF export, you can always paste screenshots into a word processor then turn that into PDF.\n",
    "\n",
    "\n",
    "##### Academic honesty:\n",
    "- Like always, check the course's collaboration policy -- see the syllabus (on Canvas): all of the content you submit, both code and text, needs to be produced independently; do not share code or written materials, and list anyone you worked with for discussions.  We will check code for plagiarism and we will follow up collaboration policy violations with the university’s Academic Honesty Policy and Procedures.\n",
    "\n",
    "This homework was originally created by Brendan O'Connor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell! It sets some things up for you.\n",
    "\n",
    "# This code makes plots appear inline in this document rather than in a new window.\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# This code imports your work from hw1.py\n",
    "from hw1 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 4) # set default size of plots\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! You have 12500 pos reviews in /home/chakew/Downloads/spring_2026/cs485/hw1/large_movie_review_dataset/train/pos\n",
      "Great! You have 12500 neg reviews in /home/chakew/Downloads/spring_2026/cs485/hw1/large_movie_review_dataset/train/neg\n"
     ]
    }
   ],
   "source": [
    "# download the IMDB large movie review corpus to a file location on your computer\n",
    "\n",
    "PATH_TO_DATA = '/home/chakew/Downloads/spring_2026/cs485/hw1/large_movie_review_dataset'  # set this variable to point to the location of the IMDB corpus on your computer\n",
    "POS_LABEL = 'pos'\n",
    "NEG_LABEL = 'neg'\n",
    "TRAIN_DIR = os.path.join(PATH_TO_DATA, \"train\")\n",
    "TEST_DIR = os.path.join(PATH_TO_DATA, \"test\")\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    if len(os.listdir(TRAIN_DIR + \"/\" + label)) == 12500:\n",
    "        print(\"Great! You have 12500 {} reviews in {}\".format(label, TRAIN_DIR + \"/\" + label))\n",
    "    else:\n",
    "        print(\"Oh no! Something is wrong. Check your code which loads the reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right away, this film was ridiculous. Not that it didn't have redeeming aspects",
      " For example, the best thing about this film was the beautiful background scenery. Anyone not living on the East Coast should know the South doesn't have beautiful mountains like those found in the West. I knew it was Utah right off the bat, but perhaps Dalton couldn't suppress his English accent, so they had to excuse it by saying this was a southern town. Subverting his accent into a Southern one was easier. Sure the film has plot twists, but its phony sense of place was something I couldn't get past. It's not like Utah doesn't have meth labs... so why the writers thought it necessary to pretend it was in the South is beyond me. <br /><br />One other thing in action pictures always puzzles me. Why do they always make the \"cocking\" sound effect when the character pulls out an automatic handgun? It seemed every other sound effect in this movie was a \"chuk-chich\" signifying a 9mm was loaded and ready to fire. Of course, the weapons already had rounds chambered so this was unnecessary. <br /><br />Lastly, the pyrotechnics were WAY over the top. But hey, this film was targeted to a certain 'market segment' I suppose... It's too bad. Each of the actors can act, but this film was lame.\n"
     ]
    }
   ],
   "source": [
    "# Actually reading the data you are working with is an important part of NLP! Let's look at one of these reviews\n",
    "\n",
    "print (open(TRAIN_DIR + \"/neg/3740_2.txt\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One: Intro to NLP in Python: types, tokens and Unix commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types and tokens\n",
    "\n",
    "One major part of any NLP project is word tokenization. Word tokenization is the task of segmenting text into individual words, called tokens. In this assignment, we will use simple whitespace tokenization. You will have a chance to improve this for extra credit at the end of the assigment. Take a look at the `tokenize_doc` function in `hw1.py`. **You should not modify tokenize_doc** but make sure you understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer\n",
      "science\n",
      "is\n",
      "both\n",
      "practical\n",
      "and\n",
      "abstract.\n"
     ]
    }
   ],
   "source": [
    "# We have provided a tokenize_doc function in hw1.py. Here is a short demo of how it works\n",
    "\n",
    "d1 = \"This SAMPLE doc has   words tHat  repeat repeat\"\n",
    "bow = tokenize_doc(d1)\n",
    "\n",
    "assert bow['this'] == 1\n",
    "assert bow['sample'] == 1\n",
    "assert bow['doc'] == 1\n",
    "assert bow['has'] == 1\n",
    "assert bow['words'] == 1\n",
    "assert bow['that'] == 1\n",
    "assert bow['repeat'] == 2\n",
    "\n",
    "bow2 = tokenize_doc(\"Computer science is both practical and abstract.\")\n",
    "for b in bow2:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1 (5 points)**\n",
    "\n",
    "Now we are going to count the word types and word tokens in the corpus. In the cell below, use the `word_counts` dictionary variable to store the count of each word in the corpus.\n",
    "Use the `tokenize_doc` function to break documents into tokens. \n",
    "\n",
    "`word_counts` keeps track of how many times a word type appears across the corpus. For instance, `word_counts[\"dog\"]` should store the number 990 -- the count of how many times the word `dog` appears in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import codecs\n",
    "from collections import defaultdict, Counter\n",
    "word_counts = Counter() # Counters are often useful for NLP in python. Similar to dicts (you can also use those)\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    for directory in [TRAIN_DIR, TEST_DIR]:\n",
    "        for fn in glob.glob(directory + \"/\" + label + \"/*.txt\"):\n",
    "            doc = open(fn, 'r', encoding='utf8') # Open the file with UTF-8 encoding\n",
    "            text = doc.read()\n",
    "            bow = tokenize_doc(text)\n",
    "            word_counts.update(bow)\n",
    "            doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay! there are 61492.0 total instances of the word type movie in the corpus\n"
     ]
    }
   ],
   "source": [
    "if word_counts[\"movie\"] == 61492:\n",
    "    print (\"yay! there are {} total instances of the word type movie in the corpus\".format(word_counts[\"movie\"]))\n",
    "else:\n",
    "    print (\"hmm. Something seems off. Double check your code\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2 (5 points)**\n",
    "\n",
    "Fill out the functions `n_word_types` and `n_word_tokens` in `hw1.py`. These functions return the total number of word types and tokens in the corpus. **important** The autoreload \"magic\" that you setup early in the assignment should automatically reload functions as you make changes and save. If you run into trouble you can always restart the notebook and clear any .pyc files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 390931 word types in the corpus\n",
      "there are 11557847.0 word tokens in the corpus\n"
     ]
    }
   ],
   "source": [
    "print (\"there are {} word types in the corpus\".format(n_word_types(word_counts)))\n",
    "print (\"there are {} word tokens in the corpus\".format(n_word_tokens(word_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between word types and tokens? Why are the number of tokens much higher than the number of types?\n",
    "\n",
    "***Answer in one or two sentences here.***\n",
    "\n",
    "*Answer:*\n",
    "Word Type: Only store unique words, don't count duplicate words.\n",
    "Word Tokens: Store any Words, count duplicate words.\n",
    "\n",
    "*Proof:*\n",
    "\n",
    "Statement: Number of tokens much higher than the number of types.\n",
    "\n",
    "For any instance, we have $N$ tokens and $V$ types, for any types we choose the first position in the instance, thus we have $V$ distinct types, so we can conclude that: $N \\ge V$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3 (5 points)**\n",
    "\n",
    "Using `word_counts` dictionary you just created, make a new list of (word,count) pairs called `sorted_list` where tuples are sorted according to counts, in decending order. Then print the first 30 values from `sorted_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 638861.0), ('a', 316615.0), ('and', 313637.0), ('of', 286661.0), ('to', 264573.0), ('is', 204876.0), ('in', 179807.0), ('i', 141587.0), ('this', 138483.0), ('that', 130140.0), ('it', 129614.0), ('/><br', 100974.0), ('was', 93258.0), ('as', 88242.0), ('with', 84590.0), ('for', 84510.0), ('but', 77864.0), ('on', 62890.0), ('movie', 61492.0), ('are', 57009.0), ('his', 56870.0), ('not', 56765.0), ('you', 55600.0), ('film', 55086.0), ('have', 54423.0), ('he', 51062.0), ('be', 50901.0), ('at', 45259.0), ('one', 44983.0), ('by', 43359.0)]\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENT ME!\n",
    "import operator\n",
    "sorted_list = sorted(word_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "print(sorted_list[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unix Text Processing\n",
    "\n",
    "In this part, you will practice extracting and processing information from text with Unix commands. The file `lotr_script.txt` is included with the zip file for this homework. This text file corresponds to the movie script of *The Fellowship of the Rings* (2001). This script comes from a larger corpus of movie scripts, the [ScriptBase-J](https://github.com/EdinburghNLP/scriptbase) corpus.\n",
    "\n",
    "First, let's open and examine `lotr_script.txt`.\n",
    "\n",
    "**Question 1.4 (5 points)**\n",
    "\n",
    "Describe the structure of this script. How are roles, scene directions, and dialogue organized?\n",
    "\n",
    "***Answer in one or two sentences here.***\n",
    "\n",
    "This script typically begins with transition marks, introducing the location and time of the scene, followed by actions, shots, and time sequences to set the stage, and the dialogue usually begins with the character's name centered, followed by their lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've identified this file's structure, let's use Unix commands to process & analyze its contents.\n",
    "\n",
    "You may want to take revisit the optional reading Ken Church, \"Unix for Poets\", available on Canvas under \"Files\" -> \"Lectures\" -> \"1-normalization\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5 (5 points)**\n",
    "\n",
    "Use Unix commands to print the name of each character with dialogue in the script, one name per line. This script's text isn't perfect, so expect a few additional names.\n",
    "\n",
    "Implement this in `hw1.sh`. Then, copy your implementation and its resulting output into the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (297198670.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m***Copy Unix commands here***\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "***Copy Unix commands here***\n",
    "\n",
    "grep -E \"^[[:space:]]{10,}[A-Z][A-Z0-9 .,'-]*([[:space:]]*\\\\([^)]*\\\\))?[[:space:]]*$\" lotr_script.txt |\n",
    "\tsed -E 's/^ +//; s/ *\\([^)]*\\)//g; s/ +$//; s/  +/ /g' |\n",
    "\tsort -u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (738548914.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m***Copy output here***\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "***Copy output here***\n",
    "Question 1.5\n",
    "ARAGORN\n",
    "ARWEN\n",
    "BILBO\n",
    "BLACK RIDER\n",
    "BOROMIR\n",
    "BUTTERBUR\n",
    "CELEBORN\n",
    "ELROND\n",
    "FARMER MAGGOT\n",
    "FRO DO\n",
    "FRODO\n",
    "FRODO DISAPPEARS\n",
    "GALADRIEL\n",
    "GANDALF\n",
    "GATEKEEPER\n",
    "GIMLI\n",
    "GOLLUM\n",
    "HALDIR\n",
    "HOBBIT BOUNDER\n",
    "ISILDUR\n",
    "LEGOLAS\n",
    "LURTZ\n",
    "MERRY\n",
    "ODO PROUDFOOT\n",
    "ORC OVERSEER\n",
    "PIPPIN\n",
    "SAM\n",
    "SARUMAN\n",
    "STRIDER\n",
    "WITCH KING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6 (5 points)**\n",
    "\n",
    "Now, let's extract and analyze the *dialogue* of this script using Unix commands\n",
    "\n",
    "First, extract all lines of dialogue in this script.\n",
    "Then, normalize and tokenize this text such that all alphabetic characters are converted to lowercase and words are sequences of alphabetic characers.\n",
    "Finally, print the top-20 most frequent word types and their corresponding counts.\n",
    "\n",
    "Hint: Ignore parantheticals. These contain short stage directions.\n",
    "\n",
    "\n",
    "Implement this in `hw1.sh`. Then, copy your implementation and its resulting output into the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (319315575.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mawk '\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "***Copy Unix commands here***\n",
    "awk '\n",
    "BEGIN{d=0}\n",
    "{\n",
    "  if (match($0,/^[[:space:]]+/) && RLENGTH>=10) {\n",
    "    name = substr($0, RLENGTH+1)\n",
    "    if (name ~ /^[A-Z][A-Z0-9 .-]*(\\([^)]*\\))?[[:space:]]*$/) {\n",
    "      d=1; next\n",
    "    }\n",
    "  }\n",
    "}\n",
    "d && /^[[:space:]]*$/ { d=0; next }\n",
    "d {\n",
    "  line=$0\n",
    "  sub(/^[[:space:]]+/, \"\", line)\n",
    "  if (line ~ /^\\(/) next\n",
    "  print $0\n",
    "}\n",
    "' lotr_script.txt |\n",
    "\ttr 'A-Z' 'a-z' |\n",
    "\tgrep -oE '[a-z]+' |\n",
    "\tsort |\n",
    "\tuniq -c |\n",
    "\tsort -nr |\n",
    "\thead -20\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1204445564.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m***Copy output here***\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "***Copy output here***\n",
    "Question 1.6\n",
    "    462 the\n",
    "    266 you\n",
    "    242 i\n",
    "    231 of\n",
    "    212 to\n",
    "    192 it\n",
    "    151 and\n",
    "    148 is\n",
    "    144 a\n",
    "    137 s\n",
    "    133 frodo\n",
    "     99 we\n",
    "     91 in\n",
    "     86 my\n",
    "     80 not\n",
    "     79 he\n",
    "     78 what\n",
    "     78 have\n",
    "     77 that\n",
    "     75 will"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7 (5 points)**\n",
    "\n",
    "If we instead tokenized *all* text in the script, how might the results from Question 1.6 to change? Are there specific word types that might become more frequent?\n",
    "\n",
    "\n",
    "***Answer in one or two sentences here.***\n",
    "\n",
    "Word frequency will likely point to directional words, like cut, night, day, scene, and camera becoming more frequent, while dialogue pronouns will be relatively less dominant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipf's Law\n",
    "\n",
    "**Question 1.8 (10 points)**\n",
    "\n",
    "In this section, you will verify a key statistical properties of text: [Zipf's Law](https://en.wikipedia.org/wiki/Zipf%27s_law).\n",
    "\n",
    "Zipf's Law describes the relations between the frequency rank of words and frequency value of words.  For a word $w$, its frequency is inversely proportional to its rank:\n",
    "\n",
    "$$count_w = K \\frac{1}{rank_w}$$\n",
    "\n",
    "$K$ is a constant, specific to the corpus and how words are being defined.\n",
    "\n",
    "***What would this look like if you took the log of both sides of the equation?***\n",
    "\n",
    "* ***Write your answer in one or two lines here.***\n",
    "\n",
    "$$log(count_w) = log(K) - log(rank_w)$$\n",
    "\n",
    "\n",
    "Therefore, if Zipf's Law holds, after sorting the words descending on frequency, word frequency decreases in an approximately linear fashion under a log-log scale.\n",
    "\n",
    "***Now, please make log-log plots for both corpora. On each, plot the log-rank versus log-frequency.***  \n",
    "Then make a plot for the movie reviews corpus.  Then make a plot for the script.  For this question, use the same Python-based analysis for both, so they're comparable.  *Hint:* Make use of a sorted list of .items() from the word counts dictionary or Counter.\n",
    "\n",
    "*Please remember to label the meaning of the x-axis and y-axis, and give a title to make clear which corpus is being shown.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAGJCAYAAAAQbJOQAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOdhJREFUeJzt3XlYVGX/BvB7AFlEGARlUwQUNBHF3Z9LaUnhkmVvam6ElvbmEira6wouqZiVmhtqi3t7YuZWuC+5gIhpmaICmolkKosI4sz5/eHLvIMsznDOzJnl/lzXXFdz5pyH75hx95zzLApBEAQQERERAMBG7gKIiIhMCYORiIhIC4ORiIhIC4ORiIhIC4ORiIhIC4ORiIhIC4ORiIhIC4ORiIhIC4ORiIhIC4ORrFZycjI6deoEZ2dnKBQKpKWlYdasWVAoFGXOCwgIwLBhwzTvDxw4AIVCgQMHDlTZ/rp166BQKJCZmSl98U9Q0fcwFIVCgVmzZul9XemfT0pKimS1GPN7k+Wyk7sAIjmUlJSgf//+cHR0xOLFi1GzZk34+/vLXZZJWLlyJWrWrFnmfwaIrAl7jGSVLl++jKysLEyaNAlvvfUWhg4ditq1a2PGjBm4f/++JD8jMjIS9+/fN7vAXblyJdatWyd3GUSyYY+RrFJOTg4AwM3NrcxxOzs72NlJ85+Fra0tbG1tJWmLiIyHPUayOsOGDUPXrl0BAP3794dCoUC3bt0ASPuMqqJnjAEBAXjxxRdx5MgRtG/fHo6OjmjYsCE2bNjwxPYyMzOhUCjw4YcfYvHixfD394eTkxO6du2Kc+fOPfH6hw8f4r333kOjRo3g4OCAgIAATJs2DcXFxWXq++2333Dw4EEoFIoyfza6ysrKwujRo9GkSRM4OTnBw8MD/fv3r/RZa2FhIf7973/Dw8MDrq6ueP3113Hnzp1y5+3atQtPP/00nJ2d4eLigt69e+O3337TqzYiXbDHSFbn3//+N+rVq4f58+cjOjoa7dq1g5eXl9F+/qVLl9CvXz+8+eabiIqKwueff45hw4ahTZs2aNas2ROv37BhA/Lz8zFmzBgUFRXh448/xnPPPYezZ89W+T1GjBiB9evXo1+/fpg4cSJOnDiB+Ph4nD9/HomJiQCAJUuW4J133kGtWrUwffp0AND7zyY5ORm//PILBg4ciPr16yMzMxMJCQno1q0bfv/9d9SsWbPM+WPHjoWbmxtmzZqFCxcuICEhAVlZWZpBTgCwceNGREVFISIiAu+//z4KCwuRkJCALl264PTp0wgICNCrRqIqCURWaP/+/QIA4dtvvy1zfObMmcLj/1n4+/sLUVFR5a7dv39/lT9j7dq1AgAhIyOjTFsAhEOHDmmO5eTkCA4ODsLEiROrbC8jI0MAIDg5OQl//vmn5viJEycEAMKECRMq/R5paWkCAGHEiBFl2pw0aZIAQNi3b5/mWLNmzYSuXbtWWYs2AMLMmTM17wsLC8udc+zYMQGAsGHDBs2x0j+fNm3aCA8ePNAcX7hwoQBA+OGHHwRBEIT8/HzBzc1NGDlyZJk2s7OzBaVSWeZ4Rf/+iPTFW6lERhYSEoKnn35a875u3bpo0qQJrly5otP1ffv2Rb169TTv27dvjw4dOmDnzp2VXlP6WUxMTJnjEydOBADs2LFD5/qfxMnJSfPPJSUl+OeffxAUFAQ3NzekpqaWO/+tt95CjRo1NO9HjRoFOzs7Tc1JSUm4e/cuBg0ahFu3bmletra26NChA/bv3y9Z7UQAb6USGV2DBg3KHatdu3aFz9UqEhwcXO5Y48aN8c0331R6TVZWFmxsbBAUFFTmuLe3N9zc3JCVlaXTz9bF/fv3ER8fj7Vr1+L69esQBEHzWW5ubrnzH/8+tWrVgo+Pj+aZZHp6OgDgueeeq/Dnubq6SlQ50SMMRiIjq2ykqnaAGIoxJr+/8847WLt2LcaPH4+OHTtCqVRCoVBg4MCBUKvVerdXes3GjRvh7e1d7nOpRhETleLfKCIzU9qD0nbx4sUqB6D4+/tDrVYjPT0dTZs21Ry/efMm7t69W2aupdjw/O677xAVFYWPPvpIc6yoqAh3796t8Pz09HQ8++yzmvcFBQW4ceMGevXqBQBo1KgRAMDT0xPh4eGiaiPSBZ8xEpmZrVu34vr165r3J0+exIkTJ9CzZ89KrykNmSVLlpQ5vmjRIgBA7969NcecnZ0rDTFd2Nraluv9Llu2DCqVqsLz16xZg5KSEs37hIQEPHz4UPN9IiIi4Orqivnz55c5r9Tff/9d7VqJKsIeI5GZCQoKQpcuXTBq1CgUFxdjyZIl8PDwwH/+859KrwkLC0NUVBTWrFmDu3fvomvXrjh58iTWr1+Pvn37lumxtWnTBgkJCZg7dy6CgoLg6elZ6fO9irz44ovYuHEjlEolQkJCcOzYMezZswceHh4Vnv/gwQN0794dAwYMwIULF7By5Up06dIFL730EoBHzxATEhIQGRmJ1q1bY+DAgahbty6uXr2KHTt2oHPnzli+fLnO9RE9CYORyMy8/vrrsLGxwZIlS5CTk4P27dtj+fLl8PHxqfK6Tz/9FA0bNsS6deuQmJgIb29vTJ06FTNnzixzXlxcHLKysrBw4ULk5+eja9euegXjxx9/DFtbW2zevBlFRUXo3Lkz9uzZg4iIiArPX758OTZv3oy4uDiUlJRg0KBBWLp0aZlbuoMHD4avry8WLFiADz74AMXFxahXrx6efvppDB8+XOfaiHShEIzxxJ+IRMvMzERgYCA++OADTJo0Se5yiCwWnzESERFpYTASERFpYTASERFp4TNGIiIiLbL2GA8dOoQ+ffrA19cXCoUCW7durfTct99+GwqFotw8LCIiIinJGoz37t1DWFgYVqxYUeV5iYmJOH78OHx9fY1UGRERWStZ5zH27NmzytU6AOD69et455138NNPP5VZnaMyxcXFZTZeVavVuH37Njw8PIyyTiQREZkeQRCQn58PX19f2NhU3Sc06Qn+arUakZGRePfdd3XawBUA4uPjMXv2bANXRkRE5ujatWuoX79+leeYdDC+//77sLOzQ3R0tM7XTJ06tcyec7m5uWjQoAGuXbvG7WmIiKxUXl4e/Pz84OLi8sRzTTYYT506hY8//hipqal63QJ1cHCAg4NDueOurq4MRiIiK6dLnpjsPMbDhw8jJycHDRo0gJ2dHezs7JCVlYWJEydWub0OERGRGCbbY4yMjCy391pERAQiIyO5aDARERmMrMFYUFCAS5cuad5nZGQgLS0N7u7uaNCgQbltamrUqAFvb280adLE2KUSEZGVkDUYU1JSyuwDVzpoJioqCuvWrZOpKiIismayBmO3bt3K7fRdlczMTMMVQ0REBBMefENERCQHkx18Y0pUagEnM24jJ78Ini6OaB/oDlsbrqJDRGSJGIxPsPvcDcz+8XfcyC3SHPNROmJmnxD0CPWRsTIiIjIE3kqtwu5zNzBqU2qZUASA7NwijNqUit3nbshUGRERGQqDsRIqtYDZP/6OioYGlR6b/ePvUKm5nSURkSVhMFbiZMbtcj1FbQKAG7lFOJlx23hFERGRwTEYK5GTX3koVuc8IiIyDwzGSni6OEp6HhERmQcGYyXaB7rDR+mIyiZlKPBodGr7QHdjlkVERAbGYKyErY0CM/uEAEC5cCx9P7NPCOczEhFZGAZjFXqE+iBhaGt4K8veLvVWOiJhaGvOYyQiskCc4P8EPUJ98HyIN1e+ISKyEgxGHdjaKNCxkceTTyQiIrPHW6lERERaGIxERERaeCvViLhLBxGR6WMwGkl1dulgkBIRGR+D0QhKd+l4fLnx0l06Kpr6we2uiIjkwWeMBladXTp02e5KpRZw7PI/+CHtOo5d/oe7fBARSYQ9RgPTZ5eOjo08nhikCgBTtpzFrG2/Izuv4t4kb8ESEVUfg9HA9N2lQ5cgvVtYAqCkzPHS3uRbzwRi25kbvAVLRFRNvJVqYPru0lHdbayE/75WH8qo8hYsERFVjcFoYPru0mGIbawqe5ZJRETlMRgNTN9dOp4UpNWl/SyTiIgqx2A0An126agqSKVQ3Vu1RETWQiEIgkXfW8vLy4NSqURubi5cXV1lrUWf0aIVzWP0dnVA0UM1cgtLKhy1qouxzwahc1AdjlQlIquiTxYwGE1YRUGa9Hs2Rm1KBYBqhyPAkapEZF0YjFrMORgrU9mqOC+F+WDNoQwAuofmm50DEB7izR4kEVk0BqMWSwxGoPLbshWFpi7YgyQiS8Zg1GKpwViV0tA8eulvLN9/WadrSvuKFa3bSkRk7vTJAllHpR46dAh9+vSBr68vFAoFtm7dqvmspKQEkydPRvPmzeHs7AxfX1+8/vrr+Ouvv+Qr2EzY2ijQsZEHgr1cdL6Gcx2JiB6RNRjv3buHsLAwrFixotxnhYWFSE1NRWxsLFJTU7FlyxZcuHABL730kgyVmid9FwvgXEciIpnXSu3Zsyd69uxZ4WdKpRJJSUllji1fvhzt27fH1atX0aBBA2OUaNZKFwvIzi3SawRrdu59g9VERGTqzGoR8dzcXCgUCri5uVV6TnFxMYqLizXv8/LyjFCZaSpdLGDUplQooPtI1Tnbf8fV24UIqOPM3TmIyOqYTTAWFRVh8uTJGDRoUJUPTuPj4zF79mwjVmbaSlfd0Wek6p3CEizek6557+5cAy+H+aJ+7Zpwr+UAb1eGJRFZLpMZlapQKJCYmIi+ffuW+6ykpASvvvoq/vzzTxw4cKDKYKyox+jn52dVo1IrUjpSNen3bHx+NFN0e5zeQUTmxGxGpeqipKQEAwYMQFZWFpKSkp74hRwcHODq6lrmRf8bqRrXpxlWDW0Nd+caotq7wa2siMhCmXQwloZieno69uzZAw8PD7lLsgg9Qn0Q+2IzSdri9A4isjSyPmMsKCjApUuXNO8zMjKQlpYGd3d3+Pj4oF+/fkhNTcX27duhUqmQnZ0NAHB3d4e9vb1cZVsEb1fx+z5qT+/o2Ij/00JElkHWYExJScGzzz6reR8TEwMAiIqKwqxZs7Bt2zYAQMuWLctct3//fnTr1s1YZVqk6k7lqAi3siIiSyJrMHbr1g1Vjf0xkXFBFqm6UzkqknmrUKqyiIhkZ9LPGMmwKttAWV+L91zEx3su8lkjEVkEk5muYSjWuIi4vrR36si8VYgvT15Fdp7+t0eVTjXwRucAjH0umHMcicikcHcNLQxG/WnPedya9hdu33ug1/UOdjZ47ilPDP0/f/xfQw+GJBHJjsGohcEojkotYHHSRSzff+nJJ1fArWYNLPhXcy4EQESysqgJ/iQvWxsFOgfVqfb1dwtL8PamVOz8lduFEZF5YDDSE5VO7RBzQ3Tsl6ex81eukkNEpo/BSE9UOrVDDLUAjP6CS8gRkeljMJJONFM7XB1EtcMl5IjI1DEYSWc9Qn1wdEp3TAhvXO02SpeQIyIyVQxG0outjQLjwoOxamhruNWs3g4dP/3G26lEZLo4XYOqTaUWsHzfJaw+dBmFD1R6XdvSzxVdgjzRsZEH5zoSkcFxHqMWBqPhlQbkqoOXcL9Erff19rZAnzBfdAn2hLerI9oHujMoiUhSDEYtDEbjUakFLNubjiV700W146N0xMw+IVwUgIgkwwn+JAtbGwXGP98Yb3YOENXOjdwiLgpARLJhMJLkwkO8JWlnDBcFICIZMBhJcu0D3eHuXL0Rq9qE/y4KwJ4jERkTg5EkZ2ujwNyXQyVrb/QXp7E9jeFIRMbBYCSD6NXCFyOfDpCsvbFfnca8Hb9J1h4RUWUYjGQw03s3w8inAyVr75PDmXhvO8ORiAyLwUgGNb13CFYObg13Z3tJ2vvsSCb6Lj+Mo5ducc1VIjIIzmMko1CpBZzMuI3s3Ps4cukWtv96A8UP9V8MQJvSyQ7vv9qC8x2J6Ik4wV8Lg9E0qdQCjl/+B5tOZGLXuZui2lo1tDXDkYiqxAn+ZPJsbRToHFwHCUPbYuXgVqLaeueLVDwQ2fskIirFYCTZ9Wrhi5WDW1f7+hI10GTGLiz66Q8+dyQi0RiMZBJ6tfAR1XMUACzdfxlPzdjFBQGISBQGI5kMsT1HAChRCxj9Bec8ElH1MRjJpPRq4YNVQ1vDqYa4v5qc80hE1cVgJJPTI9QH52b3wIvNxY00/exIJmb/eE6iqojIWjAYySTZ2iiwfEhrrBzcGg621d+0eO3RLIxYnyxhZURk6RiMZNJ6tfDB7+/1RK9mXtVuY8/5HLy9KYUjVolIJwxGMnm2NgqsjGyL8Kae1W5j97mbaDx9J6d0ENETyRqMhw4dQp8+feDr6wuFQoGtW7eW+VwQBMTFxcHHxwdOTk4IDw9Henq6PMWS7D6NaidqUXKV8GhKR9A0BiQRVU7WYLx37x7CwsKwYsWKCj9fuHAhli5dilWrVuHEiRNwdnZGREQEioqKjFwpmYrpvUNwcW5PdAioXe02Suc8No3dhd3nbkhXHBFZBJNZK1WhUCAxMRF9+/YF8Ki36Ovri4kTJ2LSpEkAgNzcXHh5eWHdunUYOHCgTu1yrVTL9cPp6xj3dZrodrjWKpHls4i1UjMyMpCdnY3w8HDNMaVSiQ4dOuDYsWOVXldcXIy8vLwyL7JML7eqh38/I36/x5hvzvC2KhFpmGwwZmdnAwC8vMqORvTy8tJ8VpH4+HgolUrNy8/Pz6B1krym9nq036OYv8iFD1T46Oc/JKuJiMybyQZjdU2dOhW5ubma17Vr1+QuiQysVwsf/Danh6g2Vh64gu4f7ucuHURkusHo7e0NALh5s+xefTdv3tR8VhEHBwe4urqWeZHlc7K3FX1b9fKtQjSesQtvb0rmrVUiK2aywRgYGAhvb2/s3btXcywvLw8nTpxAx44dZayMTNXUXiGSPHPcfS4HjabtxEe7OaWDyBrJGowFBQVIS0tDWloagEcDbtLS0nD16lUoFAqMHz8ec+fOxbZt23D27Fm8/vrr8PX11YxcJXrc1F6PpnP8q5Wv6LaWHbiMxtN3ckoHkZWRdbrGgQMH8Oyzz5Y7HhUVhXXr1kEQBMycORNr1qzB3bt30aVLF6xcuRKNGzfW+Wdwuob1UqkFvPNFKnaeq3ywlq44pYPIvOmTBSYzj9FQGIxUUPQQobN+EtWGAsCl+b1ga1P9Bc2JSD4WMY+RSCq1HO3wZhd/UW0IAJ77YJ80BRGRSWMwklWIfTEULeqLu2OQdacIUZ9VvrgEEVkGBiNZjW1jn8abXcSNWj2Yfhud5/8sUUVEZIoYjGRVYl98NGrV29W+2m1czytBwyk7cP+BSsLKiMhUMBjJ6tjb2eD4tOfx8cCW1W5DDaBp3G4M/5y3VoksDYORrNbLLevh8vxe6NnM68knV2L/xdsIjdslYVVEJDcGI1k1WxsFEiLb4ryItVYLHqjRcvZuCasiIjkxGInwaK3V5SJurd69r0KrWbu4hByRBWAwEv3Xiy3roftTdap9/Z0iNRpN4xJyROaOwUik5bNhHdDc10VUG29vSsW21D8lqoiIjI3BSPSYH6OfQfenPEW1Ef3NGQzjYgBEZonBSFSBz4a1w7JBrUS1cSD9NoKn7uBzRyIzw2AkqkSfMF9cnt8Lro521W6jRAAaTduJ7WnXJayMiAyJwUhUBVsbBX6dFYEhHfxEtTP2qzSMWH9SoqqIyJAYjEQ6mPdKCzzXpK6oNvac/xtvrmM4Epk6BiORjj4f3l70Dh17//gbL684jAcP1RJVRURSYzAS6WHb2KdFrbEKAGeu5aHxjF2Yue1XaYoiIkkxGIn0VLrGqljrf7mG1lxKjsjkMBiJqsHWRoHMBb3hYKsQ1c7t+yo0nbFDoqqISAoMRiIRLszrhWY+4p473n8INJ2xU6KKiEgsBiORSDvGiX/ueP+hgGYzeVuVyBQwGIkkIMVzx3vFKvRYtF+iioiouhiMRBIpfe4oxh85heg4/2eJKiKi6lAIgvDEhRy3bdumc4MvvfSSqIKklpeXB6VSidzcXLi6insWRKSrwCk7IHaF1Mvze8HWRtzgHiJ6RJ8s0CkYbWx061gqFAqoVCrdqjQSBiPJpc2cJPxT+EBUG6uGtkaPUB+JKiKyXvpkgU6Jp1ardXqZWigSyelU3PNInfG8qDbe3pTKjY+JjEzUM8aioiKp6iCySO617JG5oDfE3BB9e1Mqt64iMiK9g1GlUuG9995DvXr1UKtWLVy5cgUAEBsbi88++0zyAoksQYbIQTmNpnGeI5Gx6B2M8+bNw7p167Bw4ULY29trjoeGhuLTTz+VtDgiSyJ2xGqjKVwhh8gY9A7GDRs2YM2aNRgyZAhsbW01x8PCwvDHH39IWhyRpRETjioAAQxHIoPTOxivX7+OoKCgcsfVajVKSkokKYrIkontOQZM2cFtq4gMSO9gDAkJweHDh8sd/+6779CqVStJiiqlUqkQGxuLwMBAODk5oVGjRnjvvfegwwwTIpOWuaC3qJFvjWfswtTE05LVQ0T/Y6fvBXFxcYiKisL169ehVquxZcsWXLhwARs2bMD27dslLe79999HQkIC1q9fj2bNmiElJQXDhw+HUqlEdHS0pD+LyNiuLOgtaq7jlyf+wpcn/uJCAEQS02mC/+MOHz6MOXPm4MyZMygoKEDr1q0RFxeHF154QdLiXnzxRXh5eZUZ7frqq6/CyckJmzZt0qkNTvAnU5eRcw/PLjogqo3lA1vixZb1pCmIyALpkwV69xgB4Omnn0ZSUlK1itNHp06dsGbNGly8eBGNGzfGmTNncOTIESxatKjSa4qLi1FcXKx5n5eXZ/A6icQI9HSGr6sd/sp7WO02xn6Vhu9OZWHdm50krIzIOlWrxwgAKSkpOH/+PIBHzx3btGkjaWHAowE906ZNw8KFC2FrawuVSoV58+Zh6tSplV4za9YszJ49u9xx9hjJ1Ekx4lQB8XMmiSyR5Gulavvzzz8xaNAgHD16FG5ubgCAu3fvolOnTvjqq69Qv379ahf+uK+++grvvvsuPvjgAzRr1gxpaWkYP348Fi1ahKioqAqvqajH6Ofnx2AksyDVdAyxI1+JLI1Bg7FHjx64e/cu1q9fjyZNmgAALly4gOHDh8PV1RW7d0u32aqfnx+mTJmCMWPGaI7NnTsXmzZt0nnOJJ8xkrlhOBJJT/JFxLUdPHgQCQkJmlAEgCZNmmDZsmU4dOiQ/tVWobCwsNzOHra2tlCrOYeLLFfmgt6oZW/75BOfgIsBEFWP3sHo5+dX4UR+lUoFX19fSYoq1adPH8ybNw87duxAZmYmEhMTsWjRIrzyyiuS/hwiU3NuTg8kTwsX3U7AlB3ILeTCG0T60PtW6g8//ID58+djxYoVaNu2LYBHA3HeeecdTJ48GX379pWsuPz8fMTGxiIxMRE5OTnw9fXFoEGDEBcXV2ad1qrwViqZOyl6fnUcgZRZvLVK1kvyZ4y1a9eGQvG/CcT37t3Dw4cPYWf3aLZH6T87Ozvj9u3bIsuXFoORLEFo3G4UPBC/3ymfO5K1knwe45IlS6Soi4iq6dycHvg7rxjt5u8R1U7AlB1InfE83GvpdseFyBpVex6juWCPkSyNFLdW7QFcZO+RrIhBR6VqKyoqQl5eXpkXERmWFLdDH+BRwN6X4PYskaXROxjv3buHsWPHwtPTE87Ozqhdu3aZFxEZnlTPCpvG7carS36SpC0iS6F3MP7nP//Bvn37kJCQAAcHB3z66aeYPXs2fH19sWHDBkPUSEQVkCocT2U/5JxHIi16P2Ns0KABNmzYgG7dusHV1RWpqakICgrCxo0b8eWXX2Lnzp2GqrVa+IyRLJ2UocZRq2SpDPqM8fbt22jYsCEAwNXVVTM9o0uXLpKvfENET5a5oDfqKR0laStgyg5cyi6QpC0ic6V3MDZs2BAZGRkAgKeeegrffPMNAODHH3/ULCpORMZ1dGp3nImTZj/U8CUHeWuVrJrewTh8+HCcOXMGADBlyhSsWLECjo6OmDBhAt59913JCyQi3Shr1pD0VijDkayV6HmMWVlZOHXqFIKCgtCiRQup6pIMnzGSNYr89DgOX/pHkrYuzu0JeztRM7uIZGfQbafMDYORrNX9Byo0jZNmG7g3u/gj9sVQSdoikoPkwbh06VKdf3h0dLTO5xoDg5GsXdC0HXgowU5t3vbA8TkctUrmSfJgDAwM1OkHKxQKXLlyRbcqjYTBSARcv30fnRfuk6QtTukgc8RbqVoYjET/I9WAGj53JHNjtLVSjx49iuLiYjFNEJERZS7oDcWTT3uixjN2IX7n7xK0RGR6RAVjz549cf36dalqISIjyFjQG08HeYhuZ/WhDIYjWSRRwWjhd2GJLNbGEf+H83N6iG5n9aEMPJBiZA+RCeFDAiIr5WRvK8lAmsYzdnH7KrIoooJx9erV8PLykqoWIpJB5oLeqGVvK6qNpnG7MXJDskQVEclL72CMiorSLBY+ePBgODs7S14UERnXuTk9kDwtXFQbSb/n4LXleyWqiEg+egdjbm4uwsPDERwcjPnz53PwDZGFqOvqIPrW6ok/i7jGKpk9vYNx69atuH79OkaNGoWvv/4aAQEB6NmzJ7777juUlJQYokYiMiIpnjsyHMmcVesZY926dRETE4MzZ87gxIkTCAoKQmRkJHx9fTFhwgSkp6dLXScRGZFU4ahSc+Q6mR9Rg29u3LiBpKQkJCUlwdbWFr169cLZs2cREhKCxYsXS1UjEckgc0FvuIgct95o2k5sT+PjFjIvei8JV1JSgm3btmHt2rX4+eef0aJFC4wYMQKDBw/WLLOTmJiIN954A3fu3DFI0frgknBE4khxW7StTw18N06ajZSJqsOga6XWqVMHarUagwYNwsiRI9GyZcty59y9exetWrVCRkaGXoUbAoORSDypnhlyAXKSi0GDcePGjejfvz8cHR1FFWksDEYiaTAcyZxxdw0tDEYi6VzKLkD4koOi22E4krEZbXcNIrIuQd61OJ2DLB6DkYj0JlU4Xr99X4JqiKTFYCSiapEiHDsv3MfeI5kckw/G69evY+jQofDw8ICTkxOaN2+OlJQUucsiIkj3rJDhSKbErjoXpaenY//+/cjJyYFaXXYvtri4OEkKA4A7d+6gc+fOePbZZ7Fr1y7UrVsX6enpqF27tmQ/g4jEyVzQGxf+ykfE0kOi2gmYsoODcsgk6D0q9ZNPPsGoUaNQp04deHt7Q6FQ/K8xhQKpqamSFTdlyhQcPXoUhw8frnYbHJVKZDxS9PwYjmQIBp2u4e/vj9GjR2Py5MmiitRFSEgIIiIi8Oeff+LgwYOoV68eRo8ejZEjR1Z6TXFxMYqLizXv8/Ly4Ofnx2AkMhIpwnF/TDcEenJLO5KOQadr3LlzB/379692cfq4cuUKEhISEBwcjJ9++gmjRo1CdHQ01q9fX+k18fHxUCqVmpefn59RaiWiR6To8T276ACfO5Js9O4xvvnmm2jXrh3efvttQ9WkYW9vj7Zt2+KXX37RHIuOjkZycjKOHTtW4TXsMRKZBq6UQ6ZEnx6j3oNvgoKCEBsbi+PHj6N58+aoUaNGmc+jo6P1bbJSPj4+CAkJKXOsadOm+P777yu9xsHBAQ4ODpLVQETVk7mgtyThyEE5ZGx69xgDAwMrb0yhwJUrV0QXVWrw4MG4du1amcE3EyZMwIkTJ8r0IqvCwTdE8mLPkUyBxayVmpycjE6dOmH27NkYMGAATp48iZEjR2LNmjUYMmSITm0wGInkd/ZqLvqsPCK6HYYjVZfFBCMAbN++HVOnTkV6ejoCAwMRExNT5ajUxzEYiUwHp3OQXCQPxpiYGLz33ntwdnZGTExMlecuWrRIv2oNjMFIZFoYjiQHyQffnD59GiUlJZp/roz2ZH8ioopIMSiHA3LIkEz+VqpY7DESmaavDl/GlB1/iGrjTNwLUNas8eQTyepZ1DNGsRiMRKZNbO+xjiOQMou9R6oaNyomIrMh9pborSLuzkHSYjASkeyk2viYSAoMRiIyCQxHMhUMRiIyGQxHMgU6Db7Ztm2bzg2+9NJLogqSGgffEJkfznUkqUk+KtXGRreOpUKhgEql0q1KI2EwEpknhiNJSfJRqWq1WqeXqYUiEZkv3lYlufAZIxGZrMwFvbFhaDtRbTAcSV863UpdunSpzg1KuR+jFHgrlcgyiA043la1bpI/Y6xqD8YyjUm8H6MUGIxEloPhSNXFJeG0MBiJLIvYcFzycij6dvSXqBoyF1wSjogslthe3/gfzvG5I1WJ+zESkVnidA7Sh0H3Y0xNTa1030Xux0hExsJ9HclQdOox/vrrrwgNDdV5or8pYY+RyLKx50i6kPwZY6tWrXDr1i0AQMOGDfHPP/+Ir5KISAJcCICkplMwurm5ISMjAwCQmZkJtVpt0KKIiPTBcCQp6fSM8dVXX0XXrl3h4+MDhUKBtm3bwtbWtsJzTW0eIxFZBz5zJKnoPI9x9+7duHTpEqKjozFnzhy4uLhUeN64ceMkLVAsPmMksi585kgVMegE/+HDh2Pp0qWVBqOpYTASWZ8Oc5Nws+CBqDYYjpaFK99oYTASWafcwhKEzflZVBsMR8vBlW+IyOopa9YQHWwckGOdGIxEZNEYjqQvBiMRWTyGI+mDwUhEVoHhSLpiMBKR1WA4ki4YjERkVRiO9CQMRiKyOgxHqopZBeOCBQugUCgwfvx4uUshIjPHcKTKmE0wJicnY/Xq1WjRooXcpRCRhWA4UkXMIhgLCgowZMgQfPLJJ6hdu7bc5RCRBWE40uPMIhjHjBmD3r17Izw8/InnFhcXIy8vr8yLiKgqDEfSZvLB+NVXXyE1NRXx8fE6nR8fHw+lUql5+fn5GbhCIrIEDEcqZdLBeO3aNYwbNw6bN2+Go6OjTtdMnToVubm5mte1a9cMXCURWQqGIwEmvrvG1q1b8corr5TZFFmlUkGhUMDGxgbFxcWVbphcirtrEJG+xAYcd+UwPRazu0b37t1x9uxZpKWlaV5t27bFkCFDkJaW9sRQJCKqDvYcrZtJB6OLiwtCQ0PLvJydneHh4YHQ0FC5yyMiC8ZwtF4mHYxERHJiOFonk37GKAU+YyQisfjM0fxZzDNGIiJTwJ6jdWEwEhHpgOFoPRiMREQ6YjhaBwYjEZEeGI6Wj8FIRKQnhqNlYzASEVUDw9FyMRiJiKqJ4WiZGIxERCIwHC0Pg5GISCSGo2VhMBIRSYDhaDkYjEREEmE4WgYGIxGRhBiO5o/BSEQkMYajeWMwEhEZAMPRfDEYiYgMhOFonhiMREQGxHA0PwxGIiIDYziaFwYjEZERMBzNB4ORiMhIGI7mgcFIRGREDEfTx2AkIjIyseFIhsVgJCIyM+w1GhaDkYhIBrylaroYjEREMmE4miYGIxGRjBiOpofBSEQkM4ajaWEwEhGZAIaj6WAwEhERaWEwEhGZCCl6jew5isdgJCIyIVJM/mc4isNgJCIyMQxHeZl0MMbHx6Ndu3ZwcXGBp6cn+vbtiwsXLshdFhGRwTEc5WPSwXjw4EGMGTMGx48fR1JSEkpKSvDCCy/g3r17cpdGRGRwXFNVHgpBEAS5i9DV33//DU9PTxw8eBDPPPOMTtfk5eVBqVQiNzcXrq6uBq6QiEhaUvT6GLD6ZYFJ9xgfl5ubCwBwd3ev9Jzi4mLk5eWVeRERmSveUjU+swlGtVqN8ePHo3PnzggNDa30vPj4eCiVSs3Lz8/PiFUSEUmP4WhcZnMrddSoUdi1axeOHDmC+vXrV3pecXExiouLNe/z8vLg5+fHW6lEZPZ4W7X6LO5W6tixY7F9+3bs37+/ylAEAAcHB7i6upZ5ERFZAvYcjcOkg1EQBIwdOxaJiYnYt28fAgMD5S6JiEhWDEfDM+lgHDNmDDZt2oQvvvgCLi4uyM7ORnZ2Nu7fvy93aUREsmE4GpZJP2NUKBQVHl+7di2GDRumUxucrkFElorPHHWnTxbYGammajHhzCYisggBU3ZYTTjqyqRvpRIRUeUYaIbBYCQiMmNSPW/kM8f/YTASEZk5qXqODMdHGIxERBZgYBs3SdphODIYiYgswoL+nSVry9rDkcFIRGQhOBhHGgxGIiILkrmgt2S3Va2VSU/wlwIn+BORNZLydqgl9EQtbhFxIiKSj7U9c2QwEhFZIKl7edYUjgxGIiILxXCsHgYjEZEFs4Tng8bGYCQisnCZC3ozIPXAYCQiItLCYCQiItLCeYxERFbEkANoTPl2LecxEhFRhQwZXpYyapXBSERkZRiOVeOtVCIiK2eIMDO126q8lUpERFRNDEYiIiItDEYiIiItDEYiIiItDEYiIisn9UAZUxt4oy8GIxERSRZm5h6KAIORiIj+S2yoWUIoAoCd3AUQEZHpsJRwE4M9RiIiIi0MRiIiIi0MRiIiIi18xkhERHqTc7FwQz8HNYse44oVKxAQEABHR0d06NABJ0+elLskIiKrJfcOGob++SYfjF9//TViYmIwc+ZMpKamIiwsDBEREcjJyZG7NCIiqyN3KJYyZB0mH4yLFi3CyJEjMXz4cISEhGDVqlWoWbMmPv/8c7lLIyKyKqYSiqUMVY9JB+ODBw9w6tQphIeHa47Z2NggPDwcx44dq/Ca4uJi5OXllXkRERHpyqSD8datW1CpVPDy8ipz3MvLC9nZ2RVeEx8fD6VSqXn5+fkZo1QiIrIQJh2M1TF16lTk5uZqXteuXZO7JCIiMiMmPV2jTp06sLW1xc2bN8scv3nzJry9vSu8xsHBAQ4ODsYoj4iILJBJ9xjt7e3Rpk0b7N27V3NMrVZj79696Nixo4yVERFZH1NbR9VQ9Zh0MAJATEwMPvnkE6xfvx7nz5/HqFGjcO/ePQwfPlzu0oiIrI6phKMh6zDpW6kA8Nprr+Hvv/9GXFwcsrOz0bJlS+zevbvcgBwiIjKOzAW9LXrlG4UgCIJBf4LM8vLyoFQqkZubC1dXV7nLISIiGeiTBSZ/K5WIiMiYGIxERERaGIxERERaGIxERERaGIxERERaGIxERERaTH4eo1ils1G4ywYRkfUqzQBdZihafDDm5+cDAHfZICIi5OfnQ6lUVnmOxU/wV6vV+Ouvv+Di4gKFQlHtdvLy8uDn54dr165Z1EIBlvq9AH43c2Sp3wvgd5ObIAjIz8+Hr68vbGyqfopo8T1GGxsb1K9fX7L2XF1dTfZfvBiW+r0AfjdzZKnfC+B3k9OTeoqlOPiGiIhIC4ORiIhIC4NRRw4ODpg5c6bFbYJsqd8L4HczR5b6vQB+N3Ni8YNviIiI9MEeIxERkRYGIxERkRYGIxERkRYGIxERkRYGow5WrFiBgIAAODo6okOHDjh58qTcJYkWHx+Pdu3awcXFBZ6enujbty8uXLggd1mSW7BgARQKBcaPHy93KZK4fv06hg4dCg8PDzg5OaF58+ZISUmRuyzRVCoVYmNjERgYCCcnJzRq1AjvvfeeTutamppDhw6hT58+8PX1hUKhwNatW8t8LggC4uLi4OPjAycnJ4SHhyM9PV2eYvVU1XcrKSnB5MmT0bx5czg7O8PX1xevv/46/vrrL/kKriYG4xN8/fXXiImJwcyZM5GamoqwsDBEREQgJydH7tJEOXjwIMaMGYPjx48jKSkJJSUleOGFF3Dv3j25S5NMcnIyVq9ejRYtWshdiiTu3LmDzp07o0aNGti1axd+//13fPTRR6hdu7bcpYn2/vvvIyEhAcuXL8f58+fx/vvvY+HChVi2bJncpent3r17CAsLw4oVKyr8fOHChVi6dClWrVqFEydOwNnZGRERESgqKjJypfqr6rsVFhYiNTUVsbGxSE1NxZYtW3DhwgW89NJLMlQqkkBVat++vTBmzBjNe5VKJfj6+grx8fEyViW9nJwcAYBw8OBBuUuRRH5+vhAcHCwkJSUJXbt2FcaNGyd3SaJNnjxZ6NKli9xlGETv3r2FN954o8yxf/3rX8KQIUNkqkgaAITExETNe7VaLXh7ewsffPCB5tjdu3cFBwcH4csvv5Shwup7/LtV5OTJkwIAISsryzhFSYQ9xio8ePAAp06dQnh4uOaYjY0NwsPDcezYMRkrk15ubi4AwN3dXeZKpDFmzBj07t27zL87c7dt2za0bdsW/fv3h6enJ1q1aoVPPvlE7rIk0alTJ+zduxcXL14EAJw5cwZHjhxBz549Za5MWhkZGcjOzi7z91KpVKJDhw4W9zsFePR7RaFQwM3NTe5S9GLxi4iLcevWLahUKnh5eZU57uXlhT/++EOmqqSnVqsxfvx4dO7cGaGhoXKXI9pXX32F1NRUJCcny12KpK5cuYKEhATExMRg2rRpSE5ORnR0NOzt7REVFSV3eaJMmTIFeXl5eOqpp2BrawuVSoV58+ZhyJAhcpcmqezsbACo8HdK6WeWoqioCJMnT8agQYNMemHxijAYCWPGjMG5c+dw5MgRuUsR7dq1axg3bhySkpLg6OgodzmSUqvVaNu2LebPnw8AaNWqFc6dO4dVq1aZfTB+88032Lx5M7744gs0a9YMaWlpGD9+PHx9fc3+u1mjkpISDBgwAIIgICEhQe5y9MZbqVWoU6cObG1tcfPmzTLHb968CW9vb5mqktbYsWOxfft27N+/X9LtueRy6tQp5OTkoHXr1rCzs4OdnR0OHjyIpUuXws7ODiqVSu4Sq83HxwchISFljjVt2hRXr16VqSLpvPvuu5gyZQoGDhyI5s2bIzIyEhMmTEB8fLzcpUmq9PeGJf9OKQ3FrKwsJCUlmV1vEWAwVsne3h5t2rTB3r17NcfUajX27t2Ljh07yliZeIIgYOzYsUhMTMS+ffsQGBgod0mS6N69O86ePYu0tDTNq23bthgyZAjS0tJga2srd4nV1rlz53JTai5evAh/f3+ZKpJOYWFhuc1jbW1toVarZarIMAIDA+Ht7V3md0peXh5OnDhh9r9TgP+FYnp6Ovbs2QMPDw+5S6oW3kp9gpiYGERFRaFt27Zo3749lixZgnv37mH48OFylybKmDFj8MUXX+CHH36Ai4uL5vmGUqmEk5OTzNVVn4uLS7nnpM7OzvDw8DD756cTJkxAp06dMH/+fAwYMAAnT57EmjVrsGbNGrlLE61Pnz6YN28eGjRogGbNmuH06dNYtGgR3njjDblL01tBQQEuXbqkeZ+RkYG0tDS4u7ujQYMGGD9+PObOnYvg4GAEBgYiNjYWvr6+6Nu3r3xF66iq7+bj44N+/fohNTUV27dvh0ql0vxecXd3h729vVxl60/uYbHmYNmyZUKDBg0Ee3t7oX379sLx48flLkk0ABW+1q5dK3dpkrOU6RqCIAg//vijEBoaKjg4OAhPPfWUsGbNGrlLkkReXp4wbtw4oUGDBoKjo6PQsGFDYfr06UJxcbHcpelt//79Ff63FRUVJQjCoykbsbGxgpeXl+Dg4CB0795duHDhgrxF66iq75aRkVHp75X9+/fLXbpeuO0UERGRFj5jJCIi0sJgJCIi0sJgJCIi0sJgJCIi0sJgJCIi0sJgJCIi0sJgJCIi0sJgJCIi0sJgJKsnCALeeustuLu7Q6FQIC0tDd26dcP48eM15wQEBGDJkiWa9wqFAlu3bq20zcevNydial+3bp3ee+89/mdbHbNmzULLli1FtUFUimulktXbvXs31q1bhwMHDqBhw4aoU6cOtmzZgho1alS7TbHXy8mcayeSAoORrN7ly5fh4+ODTp06aY65u7uLalPs9XIy59qJpMBbqWTVhg0bhnfeeQdXr16FQqFAQEAAAPG3Qiu6FTt//ny88cYbcHFxQYMGDarcFePvv/+Gt7e3ZlNiAPjll19gb29fZsuixyUnJ+P5559HnTp1oFQq0bVrV6Smpmo+P3DgAOzt7XH48GHNsYULF8LT01OzR+Djta9cuRLBwcFwdHSEl5cX+vXrp/Ofw+XLl/Hyyy/Dy8sLtWrVQrt27bBnz55y5+Xn52PQoEFwdnZGvXr1sGLFijKf3717FyNGjEDdunXh6uqK5557DmfOnNG5DiJ9MBjJqn388ceYM2cO6tevjxs3biA5OdlgP+ujjz5C27Ztcfr0aYwePRqjRo0qt79iqbp16+Lzzz/HrFmzkJKSgvz8fERGRmLs2LHo3r17pT8jPz8fUVFROHLkCI4fP47g4GD06tUL+fn5AP4XepGRkcjNzcXp06cRGxuLTz/9FF5eXuXaS0lJQXR0NObMmYMLFy5g9+7deOaZZ3T+zgUFBejVqxf27t2L06dPo0ePHujTp0+5zZU/+OADhIWF4fTp05gyZQrGjRuHpKQkzef9+/dHTk4Odu3ahVOnTqF169bo3r07bt++rXMtRDqTeXcPItktXrxY8Pf3L3Ps8a2q/P39hcWLF2veAxASExMrbbOi64cOHap5r1arBU9PTyEhIaHK2kaPHi00btxYGDx4sNC8eXOhqKhIl6+koVKpBBcXF+HHH3/UHCsuLhZatmwpDBgwQAgJCRFGjhxZae3ff/+94OrqKuTl5en089auXSsolcoqz2nWrJmwbNkyzXt/f3+hR48eZc557bXXhJ49ewqCIAiHDx8WXF1dy333Ro0aCatXrxYEQRBmzpwphIWF6VQj0ZOwx0hkJC1atND8s0KhgLe3N3Jycqq85sMPP8TDhw/x7bffYvPmzXBwcAAAXL16FbVq1dK8Sm+53rx5EyNHjkRwcDCUSiVcXV1RUFBQpodmb2+PzZs34/vvv0dRUREWL15c6c9//vnn4e/vj4YNGyIyMhKbN29GYWGhzt+5oKAAkyZNQtOmTeHm5oZatWrh/Pnz5XqMj+9e37FjR5w/fx4AcObMGRQUFMDDw6PMd87IyMDly5d1roVIVxx8Q2Qkj4/0VCgUUKvVVV5z+fJl/PXXX1Cr1cjMzETz5s0BAL6+vkhLS9OcVzpgJioqCv/88w8+/vhj+Pv7w8HBAR07dsSDBw/KtPvLL78AAG7fvo3bt2/D2dm5wp/v4uKC1NRUHDhwAD///DPi4uIwa9YsJCcn6zQtY9KkSUhKSsKHH36IoKAgODk5oV+/fuXqqUpBQQF8fHxw4MCBcp/pOzWESBcMRiIT9eDBAwwdOhSvvfYamjRpghEjRuDs2bPw9PSEnZ0dgoKCyl1z9OhRrFy5Er169QIAXLt2Dbdu3SpzzuXLlzFhwgR88skn+PrrrxEVFYU9e/bAxqbiG0h2dnYIDw9HeHg4Zs6cCTc3N+zbtw//+te/nvgdjh49imHDhuGVV14B8CjkMjMzy513/Pjxcu+bNm0KAGjdujWys7NhZ2enGRxFZEi8lUpkoqZPn47c3FwsXboUkydPRuPGjfHGG29UeU1wcDA2btyI8+fP48SJExgyZAicnJw0n6tUKgwdOhQREREYPnw41q5di19//RUfffRRhe1t374dS5cuRVpaGrKysrBhwwao1Wo0adJEp+8QHByMLVu2IC0tDWfOnMHgwYMr7CUfPXoUCxcuxMWLF7FixQp8++23GDduHAAgPDwcHTt2RN++ffHzzz8jMzMTv/zyC6ZPn46UlBSd6iDSB4ORyAQdOHAAS5YswcaNG+Hq6gobGxts3LgRhw8fRkJCQqXXffbZZ7hz5w5at26NyMhIREdHw9PTU/P5vHnzkJWVhdWrVwMAfHx8sGbNGsyYMaPC6Q9ubm7YsmULnnvuOTRt2hSrVq3Cl19+iWbNmun0PRYtWoTatWujU6dO6NOnDyIiItC6dety502cOBEpKSlo1aoV5s6di0WLFiEiIgLAo1vOO3fuxDPPPIPhw4ejcePGGDhwILKysiocSUsklkIQBEHuIoiIiEwFe4xERERaGIxERERaGIxERERaGIxERERaGIxERERaGIxERERaGIxERERaGIxERERaGIxERERaGIxERERaGIxERERa/h9GVVKQbxe4jwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting starter code; for just one plot. change everything\n",
    "import numpy as np\n",
    "def make_graph(word_counts):\n",
    "    sorted_list = sorted(word_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    words = [w for (w, _) in sorted_list]\n",
    "    counts = [c for (_, c) in sorted_list]\n",
    "    rank = list(range(1, len(words) + 1))\n",
    "    x = np.log(rank)\n",
    "    y = np.log(counts)\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel(\"fill in x-axis label\")\n",
    "    plt.ylabel(\"fill in y-label\")\n",
    "    plt.title(\"fill in plot label\")\n",
    "    \n",
    "make_graph(word_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra credit:**  Try making a Zipf plot on bigrams, that is, where you take counts of pairs of neighboring words, instead of counting individual words.  (For example, \"I loved the movie\" has the bigrams \"I_loved\", \"loved_the\", and \"the_movie\").  What changes or stays the same?  Does the result appear to follow Zipf's law?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the homework will walk you through coding a Naive Bayes classifier that can distinguish between postive and negative reviews (at some level of accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1 (5 pts)** To start, implement the `update_model` function and `tokenize_and_update_model` function in `hw1.py`. Make sure to read the function comments so you know what to update. Also review the NaiveBayes class variables in the `def __init__` method of the NaiveBayes class  to get a sense of which statistics are important to keep track of. Once you have implemented `update_model` and `tokenize_and_update_model`, run the train model function using the code below. You’ll need to provide the path to the dataset you downloaded to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(PATH_TO_DATA, tokenizer=tokenize_doc)\n",
    "nb.train_model()\n",
    "\n",
    "if len(nb.vocab) == 251637:\n",
    "    print(\"Great! The vocabulary size is {}\".format(251637))\n",
    "else:\n",
    "    print(\"Oh no! Something seems off. Double check your code before continuing. Maybe a mistake in update_model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis\n",
    "\n",
    "Let’s begin to explore the count statistics stored by the update model function. Implement `top_n` function in the Naive Bayes Block to find the top 10 most common words in the positive class and top 10 most common words in the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 10 WORDS FOR CLASS \" + POS_LABEL + \":\")\n",
    "for tok, count in nb.top_n(POS_LABEL, 10):\n",
    "    print('', tok, count)\n",
    "print()\n",
    "\n",
    "print(\"TOP 10 WORDS FOR CLASS \" + NEG_LABEL + \":\")\n",
    "for tok, count in nb.top_n(NEG_LABEL, 10):\n",
    "    print('', tok, count)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2 (5 points)**\n",
    "\n",
    "What is the first thing that you notice when you look at the top 10 words for the 2 classes? Are these words helpful for discriminating between the two classes? Do you imagine that processing other English text will result in a similar phenomenon? What about other languages?\n",
    "\n",
    "***Answer in one or two lines here.***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3 (5 pts)**\n",
    "\n",
    "The Naive Bayes model assumes that all features are conditionally independent given the class label. For our purposes, this means that the probability of seeing a particular word in a document with class label $y$ is independent of the rest of the words in that document. Implement the `p_word_given_label` function. This function calculates P (w|y) (i.e., the probability of seeing word w in a document given the label of that document is y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your `p_word_given_label` function to compute the probability of seeing the word “amazing” given each sentiment label. Repeat the computation for the word “dull.” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P('amazing'|pos):\",  nb.p_word_given_label(\"amazing\", POS_LABEL))\n",
    "print(\"P('amazing'|neg):\",  nb.p_word_given_label(\"amazing\", NEG_LABEL))\n",
    "print(\"P('dull'|pos):\",  nb.p_word_given_label(\"dull\", POS_LABEL))\n",
    "print(\"P('dull'|neg):\",  nb.p_word_given_label(\"dull\", NEG_LABEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which word has a higher probability given the positive class, fantastic or boring? Which word has a higher probability given the negative class? Is this what you would expect?\n",
    "\n",
    "***Answer in one or two lines here.***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4 (5 pts)**\n",
    "\n",
    "In the next cell, compute the probability of the word \"car-thievery\" in the positive training data and negative training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P('car-thievery'|pos):\",  nb.p_word_given_label(\"car-thievery\", POS_LABEL))\n",
    "print(\"P('car-thievery'|neg):\",  nb.p_word_given_label(\"car-thievery\", NEG_LABEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is unusual about P('car-thievery'|neg)? What would happen if we took the log of \"P('car-thievery'|neg)\"? What would happen if we multiplied \"P('car-thievery'|neg)\" by \"P('dull'|neg)\"? Why might these operations cause problems for a Naive Bayes classifier?\n",
    "\n",
    "***Answer in one or two lines here.*** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5 (5 pts)**\n",
    "\n",
    "We can address the issues from question 2.4 with add-$\\alpha$ smoothing (like add-1 smoothing except instead of adding 1 we add $\\alpha$). Implement\n",
    "`p_word_given_label_and_alpha` in the `Naive Bayes Block` and then run the next cell. Hint: look at the slides from the lecture on add-1 smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P('stop-sign.'|pos):\",  nb.p_word_given_label_and_alpha(\"stop-sign.\", POS_LABEL, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6 (5 pts) (getting ready for question 2.11)**\n",
    "\n",
    "*Prior and Likelihood* \n",
    "\n",
    "As noted before, the Naive Bayes model assumes that all words in a document are independent of one another given the document’s label. Because of this we can write the likelihood of a document as:\n",
    "\n",
    "$P(w_{d1},\\cdots,w_{dn}|y_d) = \\prod_{i=1}^{n}P(w_{di}|y_d)$\n",
    "\n",
    "However, if a document has a lot of words, the likelihood will become extremely small and we’ll encounter numerical underflow. Underflow is a common problem when dealing with probabilistic models; if you are unfamiliar with it, you can get a brief overview on [Wikipedia](https:/en.wikipedia.org/wiki/Arithmetic_underflow). To deal with underflow, a common transformation is to work in log-space.\n",
    "\n",
    "$\\log[P(w_{d1},\\cdots,w_{dn}|y_d)] = \\sum_{i=1}^{n}\\log[P(w_{di}|y_d)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `log_likelihood` function (Hint: it should make calls to the p word given label and alpha function).\n",
    "Implement the `log_prior` function. This function takes a class label and returns the log of the fraction of the training documents that are of that label.\n",
    "\n",
    "There is nothing to print out for this question. But you will use these functions in a moment..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7 (5 pts)**\n",
    "\n",
    "Naive Bayes is a model that tells us how to compute the posterior\n",
    "probability of a document being of some label (i.e.,\n",
    "$P(y_d|\\mathbf{w_d})$).  Specifically, we do so using Bayes' rule:\n",
    "\n",
    "  $P(y_d|\\mathbf{w_d}) = \\frac{P(y_d)P(\\mathbf{w_d}|y_d)}{P(\\mathbf{w_d})}$\n",
    "\n",
    "In the previous section you implemented functions to compute both\n",
    "the log prior ($\\log[P(y_d)]$) and the log likelihood\n",
    "($\\log[P( \\mathbf{w_d} |y_d)]$ ). Now, all your missing is the\n",
    "*normalizer*, $P(\\mathbf{w_d})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive the normalizer by expanding $P(\\mathbf{w_d})$. You will have to use \"MathJax\" to write out the equations. MathJax is very similar to LaTeX. 99% of the MathJax you will need to write for this course (and others at UMass) is included in the first answer of [this](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) tutorial. MathJax and LaTeX can be annoying first, but once you get a little practice, using these tools will feel like second nature.\n",
    "\n",
    "\n",
    "Derive the normalizer by expanding $P(\\mathbf{w_d})$. Fill out the answer with MathJax here\n",
    "\n",
    "***Answer in one or two lines here.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8 (5 pts)**\n",
    "\n",
    "One way to classify a document is to compute the unnormalized log posterior for both labels and take the argmax (i.e., the label that yields the higher unnormalized log posterior). The unnormalized log posterior is the sum of the log prior and the log likelihood of the document. Why don’t we need to compute the log normalizer here?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer in one or two lines here.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9 (10 pts)**\n",
    "As we saw earlier, the top 10 words from each class do not seem to tell us much about the classes. A much more informative metric, which in some ways the model actually directly uses, is the likelihood ratio, which is defined as\n",
    "\n",
    "$LR(w)=\\frac{P(w|y=\\mathrm{pos})}{P(w|y=\\mathrm{neg})}$\n",
    "\n",
    "A word with LR=3 is 3 times more likely to appear in the positive class than in the negative. A word with LR 0.33 is one-third as likely to appear in the positive class as opposed to the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the nb.likelihood_ratio function and use it to investigate the likelihood ratio of \"amazing\" and \"dull\"\n",
    "print (\"LIKELIHOOD RATIO OF 'amazing':\", nb.likelihood_ratio('amazing', 0.2))\n",
    "print (\"LIKELIHOOD RATIO OF 'dull':\", nb.likelihood_ratio('dull', 0.2))\n",
    "print (\"LIKELIHOOD RATIO OF 'and':\", nb.likelihood_ratio('and', 0.2))\n",
    "print (\"LIKELIHOOD RATIO OF 'to':\", nb.likelihood_ratio('to', 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the minimum and maximum possible values the likelihood ratio can take? Does it make sense that $LR('amazing') > LR('to')$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer in one or two lines here.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.10 (5 pts)**\n",
    "\n",
    "Find the word in the vocabulary with the highest likelihood ratio below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement me!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.11 (5 pts)**\n",
    "\n",
    "Implement the `unnormalized_log_posterior` function and the `classify` function. The `classify` function should use the unnormalized log posteriors but should not compute the normalizer. Once you implement the `classify` function, we'd like to evaluate its accuracy. `evaluate_classifier_accuracy` is implemented for you so you don't need to change that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nb.evaluate_classifier_accuracy(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.12 (5 pts)**\n",
    "\n",
    "Try evaluating your model again with a smoothing parameter of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nb.evaluate_classifier_accuracy(1000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the accuracy go up or down when alpha is raised to 1000? Why do you think this is?\n",
    "\n",
    "***Answer in one or two lines here.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.13 (5 pts)** \n",
    "\n",
    "Find a review that your classifier got wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, print out a review that your classifier got wrong. Print out the text of the review along with the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are two reasons your system might have misclassified this example? What improvements could you make that may help your system classify this example correctly? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer in one or two lines here.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.14 (5 pts)**\n",
    "\n",
    "Often times we care about multi-class classification rather than binary classification.\n",
    "\n",
    "How many counts would we need to keep track of if the model were modified to support 5-class classification?\n",
    "\n",
    "***Answer in one or two lines here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra credit (up to 10 points)**\n",
    "\n",
    "\n",
    "If you don't want to do the extra credit, you can stop here! Otherwise... keep reading...\n",
    "In this assignment, we use whitespace tokenization to create a bag-of-unigrams representation for the movie reviews. It is possible to improve this represetation to improve your classifier's performance. Use your own code or an external library such as nltk to perform tokenization, text normalization, word filtering, etc. Fill out your work in def tokenize_doc_and_more (below) and then show improvement by running the cells below.\n",
    "\n",
    "Roughly speaking, the larger performance improvement, the more extra credit. We will also give points for the effort in the evaluation and analysis process. For example, you can split the training data into training and validation set to prevent overfitting, and report results from trying different versions of features. You can also provide some qualitative examples you found in the dataset to support your choices on preprocessing steps. Whatever you choose to try, make sure to describe your method and the reasons that you hypothesize for why the method works. You can use this ipython notebook to show your work. Be sure to explain what your code is doing in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.util import ngrams\n",
    "stemmer = SnowballStemmer('english')\n",
    "# stopset = set(stopwords.words('english'))\n",
    "def tokenize_doc_and_more(doc): \n",
    "  \"\"\"\n",
    "  Return some representation of a document.\n",
    "  At a minimum, you need to perform tokenization, the rest is up to you. \n",
    "  \"\"\"\n",
    "  # Implement me!\n",
    "  bow = defaultdict(float)\n",
    "  # your code goes here\n",
    "\n",
    "  return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(PATH_TO_DATA, tokenizer=tokenize_doc_and_more)\n",
    "nb.train_model()\n",
    "nb.evaluate_classifier_accuracy(1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cells at the bottom of this notebook to explain what you did in better_tokenize_doc. Include any experiments or explanations that you used to decide what goes in your function. Doing a good job examining, explaining and justifying your work with small experiments and comments is as important as making the accuracy number go up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments and explanations go here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (torch-cu128)",
   "language": "python",
   "name": "torch-cu128"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
